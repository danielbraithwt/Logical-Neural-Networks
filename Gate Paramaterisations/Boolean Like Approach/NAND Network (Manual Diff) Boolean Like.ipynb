{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NANDNeuron():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.epsilons = np.full((n), 0.0) #np.random.uniform(-1.0, 1.001, n)#\n",
    "        self.effector = -1\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.epsilons)\n",
    "        \n",
    "    def __beforePresent__(self):\n",
    "        self.effector = -1\n",
    "        self.delta = 0\n",
    "        self.grad = np.zeros(self.n)\n",
    "    \n",
    "    def setCheckGrad(self, g):\n",
    "        self.checkGrad = g\n",
    "        \n",
    "    def setGrad(self, g):\n",
    "        self.grad += g\n",
    "        \n",
    "    def getCheckGrad(self):\n",
    "        return self.checkGrad\n",
    "    \n",
    "    def getGrad(self):\n",
    "        return self.grad\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "    \n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "    \n",
    "    def present(self, inputs):\n",
    "        self.__beforePresent__()\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        \n",
    "        mus = np.array(list(map(lambda x: self.epsilons[x] + inputs[x] - self.epsilons[x] * inputs[x], range(0, len(inputs)))))\n",
    "        self.mus = mus\n",
    "#         mus = np.array(list(map(lambda x: np.power(inputs[x], (1-self.epsilons[x])), range(0, len(inputs)))))\n",
    "        z = np.product(mus)\n",
    "        \n",
    "        y = 1 - z#np.power(np.e, z)\n",
    "        self.output = y\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def getInput(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    def getMus(self):\n",
    "        return self.mus\n",
    "    \n",
    "    def getOutput(self):\n",
    "        return self.output\n",
    "    \n",
    "    def updateWeights(self, grad):\n",
    "        self.epsilons = self.epsilons - grad\n",
    "        for i in range(0, len(self.epsilons)):\n",
    "            if self.epsilons[i] > 1:\n",
    "                self.epsilons[i] = 1\n",
    "            elif self.epsilons[i] < 0:\n",
    "                self.epsilons[i] = 0\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.epsilons\n",
    "    \n",
    "    def getEffector(self):\n",
    "        return self.effector\n",
    "\n",
    "class NANDLayer():\n",
    "    def __init__(self, inputs, nodes):\n",
    "        self.layer = []\n",
    "        \n",
    "        for i in range(0, nodes):\n",
    "            self.layer.append(NANDNeuron(inputs))\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in self.layer:\n",
    "            s += (str(l) + \" ,\")\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def getLayer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def setFolowingLayer(self, l):\n",
    "        self.folowingLayer = l\n",
    "        \n",
    "    def present(self, inputs):\n",
    "        out = []\n",
    "        for n in self.layer:\n",
    "            out.append(n.present(inputs))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backprop(self, prediction, target, output=False):\n",
    "        for n in range(0, len(self.layer)):\n",
    "            grad = None\n",
    "            if output:\n",
    "                grad = gradientOutputLayer(self.layer[n], target, prediction)\n",
    "            else:\n",
    "                grad = gradientHiddenLayer(self.layer[n], n, self.folowingLayer)\n",
    "                \n",
    "            self.layer[n].setGrad(grad)\n",
    "            self.layer[n].updateWeights(grad * 0.05)\n",
    "    \n",
    "class NANDNetwork():\n",
    "    def __init__(self, nIns, lParams, nOuts):\n",
    "        self.layers = []\n",
    "        \n",
    "        lParams.append(nOuts)\n",
    "        inputs = nIns\n",
    "        for l in lParams:\n",
    "            self.layers.append(NANDLayer(inputs, l))\n",
    "            inputs = l\n",
    "                    \n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i-1].setFolowingLayer(self.layers[i])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in range(0, len(self.layers)):\n",
    "            s += (\"Layer \" + str(l+1) + \" -> \" + str(self.layers[l]) + \"\\n\")\n",
    "            \n",
    "        return s\n",
    "        \n",
    "    def getLayers(self):\n",
    "        return self.layers\n",
    "        \n",
    "    def fowardprop(self, inputs):\n",
    "        for l in self.layers:\n",
    "            inputs = l.present(inputs)\n",
    "            \n",
    "        return inputs[0]\n",
    "            \n",
    "    def backprop(self, prediction, target):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            layer.backprop(prediction, target, i==(len(self.layers) - 1))\n",
    "    \n",
    "    \n",
    "def MSE(network, data, targets, p=False):\n",
    "    expected = np.array(list(map(lambda x: network.fowardprop(x), data)))\n",
    "    if p:\n",
    "        print(expected)\n",
    "    return (1.0/2.0) * np.sum(np.power(np.subtract(expected, targets), 2))\n",
    "\n",
    "def gradientHiddenLayer(neuron, neuronNumber, folowingLayer):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "\n",
    "    delta = 0\n",
    "    for i in range(0, len(folowingLayer.getLayer())):\n",
    "        fn = folowingLayer.getLayer()[i]\n",
    "        delta += fn.getDelta() * -(1-fn.getWeights()[neuronNumber]) * np.product(np.delete(fn.getMus(), neuronNumber))\n",
    "        \n",
    "    neuron.setDelta(delta)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = delta * -(1-neuron.getInput()[i]) * np.product(np.delete(neuron.getMus(), i))\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "    \n",
    "def gradientOutputLayer(neuron, target, prediction):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "\n",
    "    delta = -(target - prediction)\n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = delta * -(1-neuron.getInput()[i]) * np.product(np.delete(neuron.getMus(), i))\n",
    "        \n",
    "    neuron.setDelta(delta)\n",
    "    \n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNANDNetwork(data, targets, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    print(network)\n",
    "    print(\"Initial Loss: \", MSE(network, data, targets))\n",
    "    \n",
    "    pterb = 0.0000001\n",
    "    \n",
    "    for i in range(1, 10000):\n",
    "        if i%1000 == 0:\n",
    "            print(\"Iteration -> \" + str(i) + \" : \" + str(MSE(network, data, targets)))\n",
    "            \n",
    "        for i in range(0, len(network.getLayers())):\n",
    "            layer = network.getLayers()[i]\n",
    "            for j in range(0, len(layer.getLayer())):\n",
    "                neuron = layer.getLayer()[j]\n",
    "                grad = np.zeros(len(neuron.getWeights()))\n",
    "            \n",
    "                for k in range(0, len(neuron.getWeights())):\n",
    "                    g = np.zeros(len(neuron.getWeights()))\n",
    "                    g[k] = -pterb\n",
    "\n",
    "                    oldSSE = MSE(network, data, targets)\n",
    "                    neuron.updateWeights(g)\n",
    "                    newSSE = MSE(network, data, targets)\n",
    "                    neuron.updateWeights(-g)\n",
    "                \n",
    "                    grad[k] = (newSSE - oldSSE)/pterb\n",
    "                \n",
    "                neuron.updateWeights(grad * 0.02)\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(network, data, targets, True))\n",
    "    return network\n",
    "            \n",
    "            \n",
    "        \n",
    "def checkGrad(pterb, threshold, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    \n",
    "    print(\"Computing Numerical Grads\")\n",
    "    for i in range(0, len(network.getLayers())):\n",
    "        layer = network.getLayers()[i]\n",
    "        for j in range(0, len(layer.getLayer())):\n",
    "            neuron = layer.getLayer()[j]\n",
    "            grad = np.zeros(len(neuron.getWeights()))\n",
    "            \n",
    "            for k in range(0, len(neuron.getWeights())):\n",
    "                g = np.zeros(len(neuron.getWeights()))\n",
    "                g[k] = -pterb\n",
    "                \n",
    "                oldSSE = MSE(network, data, targets)\n",
    "                neuron.updateWeights(g)\n",
    "                newSSE = MSE(network, data, targets)\n",
    "                neuron.updateWeights(-g)\n",
    "                \n",
    "                grad[k] = (newSSE - oldSSE)/pterb\n",
    "                \n",
    "#             print(grad)\n",
    "            neuron.setCheckGrad(grad)\n",
    "    \n",
    "    print(\"Running Back Prop\")\n",
    "    for j in range(0, len(data)):\n",
    "        prediction = network.fowardprop(data[j])\n",
    "        network.backprop(prediction, targets[j])\n",
    "        \n",
    "        \n",
    "    print(\"Checking Grad\")\n",
    "    for i in range(0, len(network.getLayers())):\n",
    "        layer = network.getLayers()[i]\n",
    "        for j in range(0, len(layer.getLayer())):\n",
    "            neuron = layer.getLayer()[j]\n",
    "            \n",
    "            diff = np.absolute(neuron.getCheckGrad() - neuron.getGrad())\n",
    "            for k in diff:\n",
    "                if k > threshold:\n",
    "                    print(\"GRAD WRONG[ \" + str(i) + \",\" + str(j) + \" ]: Got \" + str(neuron.getGrad()) + \" Should be \" + str(neuron.getCheckGrad()))\n",
    "                    break\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NAND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  0.0\n",
      "Iteration -> 1000 : 0.0\n",
      "Iteration -> 2000 : 0.0\n",
      "Iteration -> 3000 : 0.0\n",
      "Iteration -> 4000 : 0.0\n",
      "Iteration -> 5000 : 0.0\n",
      "Iteration -> 6000 : 0.0\n",
      "Iteration -> 7000 : 0.0\n",
      "Iteration -> 8000 : 0.0\n",
      "Iteration -> 9000 : 0.0\n",
      "[ 1.  1.  1.  0.]\n",
      "Trained Loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 0.  0.] ,"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNAND = np.array([[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
    "targetsNAND = np.array([1.0,1.0,1.0,0.0])\n",
    "trainNANDNetwork(dataNAND, targetsNAND, 2, [], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NOT Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  0.0\n",
      "Iteration -> 1000 : 0.0\n",
      "Iteration -> 2000 : 0.0\n",
      "Iteration -> 3000 : 0.0\n",
      "Iteration -> 4000 : 0.0\n",
      "Iteration -> 5000 : 0.0\n",
      "Iteration -> 6000 : 0.0\n",
      "Iteration -> 7000 : 0.0\n",
      "Iteration -> 8000 : 0.0\n",
      "Iteration -> 9000 : 0.0\n",
      "[ 1.  0.]\n",
      "Trained Loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 0.  0.] ,"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNOT = np.array([[0.0, 1.0], [1.0, 1.0]])\n",
    "targetsNOT = np.array([1.0, 0.0])\n",
    "trainNANDNetwork(dataNOT, targetsNOT, 2, [], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,\n",
      "Layer 2 -> [ 0.] ,\n",
      "\n",
      "Initial Loss:  0.0\n",
      "Iteration -> 1000 : 0.0\n",
      "Iteration -> 2000 : 0.0\n",
      "Iteration -> 3000 : 0.0\n",
      "Iteration -> 4000 : 0.0\n",
      "Iteration -> 5000 : 0.0\n",
      "Iteration -> 6000 : 0.0\n",
      "Iteration -> 7000 : 0.0\n",
      "Iteration -> 8000 : 0.0\n",
      "Iteration -> 9000 : 0.0\n",
      "[ 0.  0.  0.  1.]\n",
      "Trained Loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 0.  0.] ,\n",
       "Layer 2 -> [ 0.] ,"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAND = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "targetsAND = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "trainNANDNetwork(dataAND, targetsAND, 2, [1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,[ 0.  0.] ,\n",
      "Layer 2 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  1.0\n",
      "Iteration -> 1000 : 0.156097848728\n",
      "Iteration -> 2000 : 0.144529447194\n",
      "Iteration -> 3000 : 9.80486407132e-15\n",
      "Iteration -> 4000 : 9.80486407132e-15\n",
      "Iteration -> 5000 : 9.80486407132e-15\n",
      "Iteration -> 6000 : 9.80486407132e-15\n",
      "Iteration -> 7000 : 9.80486407132e-15\n",
      "Iteration -> 8000 : 9.80486407132e-15\n",
      "Iteration -> 9000 : 9.80486407132e-15\n",
      "[ 0.         0.9999999  0.9999999  1.       ]\n",
      "Trained Loss:  9.80486407132e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 0.9999999  0.       ] ,[ 0.         0.9999999] ,\n",
       "Layer 2 -> [ 0.  0.] ,"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataOR = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "targetsOR = np.array([0.0, 1.0, 1.0, 1.0])\n",
    "trainNANDNetwork(dataOR, targetsOR, 2, [2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Implys B Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,[ 0.  0.] ,\n",
      "Layer 2 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  1.0\n",
      "Iteration -> 1000 : 0.250000005659\n",
      "Iteration -> 2000 : 0.250000005659\n",
      "Iteration -> 3000 : 0.250000005659\n",
      "Iteration -> 4000 : 0.250000005659\n",
      "Iteration -> 5000 : 0.250000005659\n",
      "Iteration -> 6000 : 0.250000005659\n",
      "Iteration -> 7000 : 0.250000005659\n",
      "Iteration -> 8000 : 0.250000005659\n",
      "Iteration -> 9000 : 0.250000005659\n",
      "[ 0.49999995  0.99999996  0.49999996  0.99999996]\n",
      "Trained Loss:  0.250000005659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 1.         0.3868138] ,[ 0.9999999   0.18672872] ,\n",
       "Layer 2 -> [  3.88484800e-06   1.14593043e-02] ,"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataI = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "targetsI = np.array([1.0, 1.0, 0.0, 1.0])\n",
    "trainNANDNetwork(dataI, targetsI, 2, [2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
