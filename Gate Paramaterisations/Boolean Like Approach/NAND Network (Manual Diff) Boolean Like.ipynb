{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NANDNeuron():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.epsilons = np.full((n), 0.0) #np.random.uniform(-1.0, 1.001, n)#\n",
    "        self.effector = -1\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.epsilons)\n",
    "        \n",
    "    def __beforePresent__(self):\n",
    "        self.effector = -1\n",
    "        self.delta = 0\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "    \n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "    \n",
    "    def present(self, inputs):\n",
    "        self.__beforePresent__()\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        \n",
    "        mus = np.array(list(map(lambda x: self.epsilons[x] + inputs[x] - self.epsilons[x] * inputs[x], range(0, len(inputs)))))\n",
    "        self.mus = mus\n",
    "#         mus = np.array(list(map(lambda x: np.power(inputs[x], (1-self.epsilons[x])), range(0, len(inputs)))))\n",
    "        z = np.product(mus)\n",
    "        \n",
    "        y = 1 - z#np.power(np.e, z)\n",
    "        self.output = y\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def getInput(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    def getMus(self):\n",
    "        return self.mus\n",
    "    \n",
    "    def getOutput(self):\n",
    "        return self.output\n",
    "    \n",
    "    def updateWeights(self, grad):\n",
    "        self.epsilons = self.epsilons - grad\n",
    "        for i in range(0, len(self.epsilons)):\n",
    "            if self.epsilons[i] > 1:\n",
    "                self.epsilons[i] = 1\n",
    "            elif self.epsilons[i] < 0:\n",
    "                self.epsilons[i] = 0\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.epsilons\n",
    "    \n",
    "    def getEffector(self):\n",
    "        return self.effector\n",
    "\n",
    "class NANDLayer():\n",
    "    def __init__(self, inputs, nodes):\n",
    "        self.layer = []\n",
    "        \n",
    "        for i in range(0, nodes):\n",
    "            self.layer.append(NANDNeuron(inputs))\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in self.layer:\n",
    "            s += (str(l) + \" ,\")\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def getLayer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def setFolowingLayer(self, l):\n",
    "        self.folowingLayer = l\n",
    "        \n",
    "    def present(self, inputs):\n",
    "        out = []\n",
    "        for n in self.layer:\n",
    "            out.append(n.present(inputs))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backprop(self, prediction, target, output=False):\n",
    "        for n in range(0, len(self.layer)):\n",
    "            grad = None\n",
    "            if output:\n",
    "                grad = gradientOutputLayer(self.layer[n], target, prediction)\n",
    "            else:\n",
    "                grad = gradientHiddenLayer(self.layer[n], n, self.folowingLayer)\n",
    "                \n",
    "            self.layer[n].updateWeights(grad * 0.05)\n",
    "    \n",
    "class NANDNetwork():\n",
    "    def __init__(self, nIns, lParams, nOuts):\n",
    "        self.layers = []\n",
    "        \n",
    "        lParams.append(nOuts)\n",
    "        inputs = nIns\n",
    "        for l in lParams:\n",
    "            self.layers.append(NANDLayer(inputs, l))\n",
    "            inputs = l\n",
    "                    \n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i-1].setFolowingLayer(self.layers[i])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in range(0, len(self.layers)):\n",
    "            s += (\"Layer \" + str(l+1) + \" -> \" + str(self.layers[l]) + \"\\n\")\n",
    "            \n",
    "        return s\n",
    "        \n",
    "    def fowardprop(self, inputs):\n",
    "        for l in self.layers:\n",
    "            inputs = l.present(inputs)\n",
    "            \n",
    "        return inputs[0]\n",
    "            \n",
    "    def backprop(self, prediction, target):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            layer.backprop(prediction, target, i==(len(self.layers) - 1))\n",
    "    \n",
    "    \n",
    "def MSE(network, data, targets, p=False):\n",
    "    expected = np.array(list(map(lambda x: network.fowardprop(x), data)))\n",
    "    if p:\n",
    "        print(expected)\n",
    "    return (1.0/2.0) * np.sum(np.power(np.subtract(expected, targets), 2))\n",
    "\n",
    "def gradientHiddenLayer(neuron, neuronNumber, folowingLayer):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "\n",
    "    delta = 0\n",
    "    for i in range(0, len(folowingLayer.getLayer())):\n",
    "        fn = folowingLayer.getLayer()[i]\n",
    "        delta += fn.getDelta() * -(1-fn.getWeights()[neuronNumber]) * np.product(np.delete(fn.getMus(), neuronNumber))\n",
    "        \n",
    "    neuron.setDelta(delta)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = delta * -(1-neuron.getInput()[i]) * np.product(np.delete(neuron.getMus(), i))\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "    \n",
    "def gradientOutputLayer(neuron, target, prediction):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "\n",
    "    delta = -(target - prediction)\n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = delta * -(1-neuron.getInput()[i]) * np.product(np.delete(neuron.getMus(), i))\n",
    "        \n",
    "    neuron.setDelta(delta)\n",
    "    \n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNANDNetwork(data, targets, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    print(network)\n",
    "    print(\"Initial Loss: \", MSE(network, data, targets))\n",
    "    \n",
    "    for i in range(1, 10000):\n",
    "#         if (MSE(network, data, targets) < 0.0000000000001):\n",
    "#             break\n",
    "#         if i%1000 == 0:\n",
    "#             print(\"Iteration -> \" + str(i))\n",
    "            \n",
    "        for j in range(0, len(data)):\n",
    "            prediction = network.fowardprop(data[j])\n",
    "            network.backprop(prediction, targets[j])\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(network, data, targets, True))\n",
    "    return network\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,[ 0.  0.] ,\n",
      "Layer 2 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  1.0\n",
      "[ 0.40514407  0.7291127   0.7264587   1.        ]\n",
      "Trained Loss:  0.15617324391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 0.47953166  0.47698824] ,[ 0.47953166  0.47698824] ,\n",
       "Layer 2 -> [ 0.  0.] ,"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAND Gate Data\n",
    "# data = np.array([[0.0,0.0,0.0],[1.0,0.0,0.0],[0.0,1.0,0.0],[1.0,1.0,0.0]])\n",
    "# targets = np.array([1.0,1.0,1.0,0.0])\n",
    "\n",
    "\n",
    "\n",
    "# NOT Gate Data\n",
    "# data = np.array([[0.0, 1.0, 0.0], [1.0, 1.0, 0.0]])\n",
    "# targets = np.array([1.0, 0.0])\n",
    "# trainNANDNetwork(data, targets, 3, [], 1)\n",
    "\n",
    "\n",
    "# AND Gate Data\n",
    "# data = np.array([[0.0, 0.0, 0.0], [0.0, 1.0,0.0], [1.0, 0.0,0.0], [1.0, 1.0,0.0]])\n",
    "# targets = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "\n",
    "# OR Gate Data \n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "targets = np.array([0.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "trainNANDNetwork(data, targets, 2, [2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
