{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NANDNeuron():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.epsilons = np.full((n), 0.0) #np.random.uniform(-0.2, 0.2, n)\n",
    "        self.effector = -1\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.epsilons)\n",
    "        \n",
    "    def __beforePresent__(self):\n",
    "        self.effector = -1\n",
    "        self.delta = 0\n",
    "        self.grad = np.zeros(self.n)\n",
    "    \n",
    "    def setCheckGrad(self, g):\n",
    "        self.checkGrad = g\n",
    "        \n",
    "    def setGrad(self, g):\n",
    "        self.grad += g\n",
    "        \n",
    "    def getCheckGrad(self):\n",
    "        return self.checkGrad\n",
    "    \n",
    "    def getGrad(self):\n",
    "        return self.grad\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "    \n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "    \n",
    "    def present(self, inputs):\n",
    "        self.__beforePresent__()\n",
    "        mus = np.maximum(self.epsilons, inputs)\n",
    "        self.mus = mus\n",
    "        self.inputs = inputs\n",
    "        out = np.min(mus)\n",
    "        \n",
    "        # Determin which had effect\n",
    "        for i in range(0, len(mus)):\n",
    "            if out == mus[i]:\n",
    "                self.effector = i\n",
    "        \n",
    "        self.output = -out\n",
    "        return self.output\n",
    "\n",
    "    def getInput(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    def getMus(self):\n",
    "        return self.mus\n",
    "    \n",
    "    def getOutput(self):\n",
    "        return self.output\n",
    "    \n",
    "    def updateWeights(self, grad):\n",
    "        self.epsilons = self.epsilons - grad\n",
    "#         for i in range(0, len(self.epsilons)):\n",
    "#             if self.epsilons[i] > 1:\n",
    "#                 self.epsilons[i] = 1\n",
    "#             elif self.epsilons[i] < -1:\n",
    "#                 self.epsilons[i] = -1\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.epsilons\n",
    "    \n",
    "    def getEffector(self):\n",
    "        return self.effector\n",
    "\n",
    "class NANDLayer():\n",
    "    def __init__(self, inputs, nodes):\n",
    "        self.layer = []\n",
    "        \n",
    "        for i in range(0, nodes):\n",
    "            self.layer.append(NANDNeuron(inputs))\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in self.layer:\n",
    "            s += (str(l) + \" ,\")\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def getLayer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def setFolowingLayer(self, l):\n",
    "        self.folowingLayer = l\n",
    "        \n",
    "    def present(self, inputs):\n",
    "        out = []\n",
    "        for n in self.layer:\n",
    "            out.append(n.present(inputs))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backprop(self, prediction, target, output=False):\n",
    "        for n in range(0, len(self.layer)):\n",
    "            grad = None\n",
    "            if output:\n",
    "                grad = gradientOutputLayer(self.layer[n], target, prediction)\n",
    "            else:\n",
    "                grad = gradientHiddenLayer(self.layer[n], n, self.folowingLayer)\n",
    "                \n",
    "            self.layer[n].setGrad(grad)\n",
    "            self.layer[n].updateWeights(grad * 1)\n",
    "    \n",
    "class NANDNetwork():\n",
    "    def __init__(self, nIns, lParams, nOuts):\n",
    "        self.layers = []\n",
    "        \n",
    "        lParams.append(nOuts)\n",
    "        inputs = nIns\n",
    "        for l in lParams:\n",
    "            self.layers.append(NANDLayer(inputs, l))\n",
    "            inputs = l\n",
    "                    \n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i-1].setFolowingLayer(self.layers[i])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in range(0, len(self.layers)):\n",
    "            s += (\"Layer \" + str(l+1) + \" -> \" + str(self.layers[l]) + \"\\n\")\n",
    "            \n",
    "        return s\n",
    "        \n",
    "    def getLayers(self):\n",
    "        return self.layers\n",
    "        \n",
    "        \n",
    "    def fowardprop(self, inputs):\n",
    "        for l in self.layers:\n",
    "            inputs = l.present(inputs)\n",
    "            \n",
    "        return inputs[0]\n",
    "            \n",
    "    def backprop(self, prediction, target):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            layer.backprop(prediction, target, i==(len(self.layers) - 1))\n",
    "    \n",
    "    \n",
    "def MSE(network, data, targets):\n",
    "    expected = np.array(list(map(lambda x: network.fowardprop(x), data)))\n",
    "#     print(expected)\n",
    "    return (1.0/2.0) * np.sum(np.power(np.subtract(expected, targets), 2))\n",
    "\n",
    "def gradientHiddenLayer(neuron, neuronNumber, folowingLayer):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    # Compute the delta of current node\n",
    "    dE_dy = 0\n",
    "    for i in range(0, len(folowingLayer.getLayer())):\n",
    "        fn = folowingLayer.getLayer()[i]\n",
    "        delta = fn.getDelta()\n",
    "        w = deltaW(neuronNumber, fn)\n",
    "#         print(w)\n",
    "        \n",
    "        dE_dy += delta * w\n",
    "        \n",
    "    \n",
    "#     print(dE_dy)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = -dE_dy * deltaW(i, neuron)\n",
    "        \n",
    "        \n",
    "    neuron.setDelta(-dE_dy)\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "    \n",
    "def gradientOutputLayer(neuron, target, prediction):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    dE_dy = -(target - prediction)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        grad[i] = -dE_dy * deltaW(i, neuron)\n",
    "    \n",
    "    neuron.setDelta(-dE_dy)\n",
    "#     print(grad)\n",
    "    return grad\n",
    "\n",
    "def UNITFUNC(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Compute W_{a,b}\n",
    "def deltaW(i, neuron):\n",
    "    muBs = np.delete(neuron.getMus(), i)\n",
    "    t = UNITFUNC(np.min(muBs) - neuron.getMus()[i]) * UNITFUNC(neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNANDNetwork(data, targets, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    print(network)\n",
    "    print(\"Initial Loss: \", MSE(network, data, targets))\n",
    "    pterb = 0.00001\n",
    "    \n",
    "    for i in range(1, 10000):\n",
    "        \n",
    "#         if (MSE(network, data, targets) < 0.0000000000001):\n",
    "#             break\n",
    "        if i%1000 == 0:\n",
    "            print()\n",
    "            print(\"Iteration -> \" + str(i))\n",
    "            print(\"Loss: \", MSE(network, data, targets))\n",
    "            \n",
    "        for i in range(0, len(network.getLayers())):\n",
    "            layer = network.getLayers()[i]\n",
    "            for j in range(0, len(layer.getLayer())):\n",
    "                neuron = layer.getLayer()[j]\n",
    "                grad = np.zeros(len(neuron.getWeights()))\n",
    "            \n",
    "                for k in range(0, len(neuron.getWeights())):\n",
    "                    g = np.zeros(len(neuron.getWeights()))\n",
    "                    g[k] = -pterb\n",
    "\n",
    "                    oldSSE = MSE(network, data, targets)\n",
    "                    neuron.updateWeights(g)\n",
    "                    newSSE = MSE(network, data, targets)\n",
    "                    neuron.updateWeights(-g)\n",
    "                \n",
    "                    grad[k] = (newSSE - oldSSE)/pterb\n",
    "                \n",
    "#             print(grad)\n",
    "                neuron.updateWeights(grad * 0.02)    \n",
    "        \n",
    "#         for j in range(0, len(data)):\n",
    "#             prediction = network.fowardprop(data[j])\n",
    "#             network.backprop(prediction, targets[j])\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(network, data, targets))\n",
    "    return network\n",
    "\n",
    "def checkGrad(pterb, threshold, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    \n",
    "    print(\"Computing Numerical Grads\")\n",
    "    for i in range(0, len(network.getLayers())):\n",
    "        layer = network.getLayers()[i]\n",
    "        for j in range(0, len(layer.getLayer())):\n",
    "            neuron = layer.getLayer()[j]\n",
    "            grad = np.zeros(len(neuron.getWeights()))\n",
    "            \n",
    "            for k in range(0, len(neuron.getWeights())):\n",
    "                g = np.zeros(len(neuron.getWeights()))\n",
    "                g[k] = -pterb\n",
    "                \n",
    "                oldSSE = MSE(network, data, targets)\n",
    "                neuron.updateWeights(g)\n",
    "                newSSE = MSE(network, data, targets)\n",
    "                neuron.updateWeights(-g)\n",
    "                \n",
    "                grad[k] = (newSSE - oldSSE)/pterb\n",
    "                \n",
    "#             print(grad)\n",
    "            neuron.setCheckGrad(grad)\n",
    "    \n",
    "    print(\"Running Back Prop\")\n",
    "    for j in range(0, len(data)):\n",
    "        prediction = network.fowardprop(data[j])\n",
    "        network.backprop(prediction, targets[j])\n",
    "        \n",
    "        \n",
    "    print(\"Checking Grad\")\n",
    "    for i in range(0, len(network.getLayers())):\n",
    "        layer = network.getLayers()[i]\n",
    "        for j in range(0, len(layer.getLayer())):\n",
    "            neuron = layer.getLayer()[j]\n",
    "            \n",
    "            diff = np.absolute(neuron.getCheckGrad() - neuron.getGrad())\n",
    "            for k in diff:\n",
    "                if k > threshold:\n",
    "                    print(\"GRAD WRONG[ \" + str(i) + \",\" + str(j) + \" ]: Got \" + str(neuron.getGrad()) + \" Should be \" + str(neuron.getCheckGrad()))\n",
    "                    break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.06210596 -0.03756047] ,[ 0.06658948  0.18025209] ,\n",
      "Layer 2 -> [-0.14062751 -0.13040974] ,\n",
      "\n",
      "Initial Loss:  1.75178830962\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c89cc76a7f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# checkGrad(0.0001, 0.0001, 2, [2], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainNANDNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-179b15e1c9aa>\u001b[0m in \u001b[0;36mtrainNANDNetwork\u001b[0;34m(data, targets, inputNodes, hLayers, outNodes)\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpterb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0moldSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mnewSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81e57aadbc44>\u001b[0m in \u001b[0;36mMSE\u001b[0;34m(network, data, targets)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfowardprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;31m#     print(expected)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81e57aadbc44>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfowardprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;31m#     print(expected)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81e57aadbc44>\u001b[0m in \u001b[0;36mfowardprop\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfowardprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81e57aadbc44>\u001b[0m in \u001b[0;36mpresent\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-81e57aadbc44>\u001b[0m in \u001b[0;36mpresent\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__beforePresent__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/pkg/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0mtapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NAND Gate Data\n",
    "# data = np.array([[-1.0,-1.0],[1.0,-1.0],[-1.0,1.0],[1.0,1.0]])\n",
    "# targets = np.array([1.0,1.0,1.0,-1.0])\n",
    "\n",
    "\n",
    "\n",
    "# NOT Gate Data\n",
    "# data = np.array([[-1.0, -1.0, -1.0], [1.0, -1.0, -1.0]])\n",
    "# targets = np.array([1.0, -1.0])\n",
    "# trainNANDNetwork(data, targets, 3, [], 1)\n",
    "\n",
    "\n",
    "# AND Gate Data\n",
    "# data = np.array([[-1.0, -1.0, 1.0], [-1.0, 1.0, 1.0], [1.0, -1.0, 1.0], [1.0, 1.0, 1.0]])\n",
    "# targets = np.array([-1.0, -1.0, -1.0, 1.0])\n",
    "\n",
    "# OR Gate Data \n",
    "data = np.array([[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0]])\n",
    "targets = np.array([-1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "# data = np.array([[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0]])\n",
    "# targets = np.array([1.0, 1.0, -1.0, 1.0])\n",
    "\n",
    "# checkGrad(0.0001, 0.0001, 2, [2], 1)\n",
    "trainNANDNetwork(data, targets, 2, [2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
