{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NANDNeuron():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.epsilons = np.full((n), 0.0) #np.random.uniform(-1.0, 1.001, n)#\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.epsilons)\n",
    "        \n",
    "    def __beforePresent__(self):\n",
    "        self.delta = 0\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "    \n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "    \n",
    "    def present(self, inputs):\n",
    "        self.__beforePresent__()\n",
    "        # Compute a \"logical\" or on inputs and weights\n",
    "        mus = (self.epsilons + inputs) - np.multiply(self.epsilons, inputs)\n",
    "\n",
    "        self.mus = mus\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        out = np.prod(mus)\n",
    "        self.output = 1 - out\n",
    "        return self.output\n",
    "\n",
    "    def getInput(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    def getMus(self):\n",
    "        return self.mus\n",
    "    \n",
    "    def getOutput(self):\n",
    "        return self.output\n",
    "    \n",
    "    def updateWeights(self, grad):\n",
    "        self.epsilons = self.epsilons - grad\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.epsilons\n",
    "    \n",
    "    def getEffector(self):\n",
    "        return self.effector\n",
    "\n",
    "class NANDLayer():\n",
    "    def __init__(self, inputs, nodes):\n",
    "        self.layer = []\n",
    "        \n",
    "        for i in range(0, nodes):\n",
    "            self.layer.append(NANDNeuron(inputs))\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in self.layer:\n",
    "            s += (str(l) + \" ,\")\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def getLayer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def setFolowingLayer(self, l):\n",
    "        self.folowingLayer = l\n",
    "        \n",
    "    def present(self, inputs):\n",
    "        out = []\n",
    "        for n in self.layer:\n",
    "            out.append(n.present(inputs))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backprop(self, prediction, target, output=False):\n",
    "        for n in range(0, len(self.layer)):\n",
    "            grad = None\n",
    "            if output:\n",
    "                grad = gradientOutputLayer(self.layer[n], target, prediction)\n",
    "            else:\n",
    "                grad = gradientHiddenLayer(self.layer[n], n, self.folowingLayer)\n",
    "                \n",
    "            self.layer[n].updateWeights(grad * 0.05)\n",
    "    \n",
    "class NANDNetwork():\n",
    "    def __init__(self, nIns, lParams, nOuts):\n",
    "        self.layers = []\n",
    "        \n",
    "        lParams.append(nOuts)\n",
    "        inputs = nIns\n",
    "        for l in lParams:\n",
    "            self.layers.append(NANDLayer(inputs, l))\n",
    "            inputs = l\n",
    "                    \n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i-1].setFolowingLayer(self.layers[i])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in range(0, len(self.layers)):\n",
    "            s += (\"Layer \" + str(l+1) + \" -> \" + str(self.layers[l]) + \"\\n\")\n",
    "            \n",
    "        return s\n",
    "        \n",
    "    def fowardprop(self, inputs):\n",
    "        for l in self.layers:\n",
    "            inputs = l.present(inputs)\n",
    "            \n",
    "        return inputs[0]\n",
    "            \n",
    "    def backprop(self, prediction, target):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            layer.backprop(prediction, target, i==(len(self.layers) - 1))\n",
    "    \n",
    "    \n",
    "def MSE(network, data, targets):\n",
    "    expected = np.array(list(map(lambda x: network.fowardprop(x), data)))\n",
    "#     print(expected)\n",
    "    return (1.0/2.0) * np.sum(np.power(np.subtract(expected, targets), 2))\n",
    "\n",
    "def gradientHiddenLayer(neuron, neuronNumber, folowingLayer):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    # Compute the delta of current node\n",
    "    dE_dy = 0\n",
    "    for i in range(0, len(folowingLayer.getLayer())):\n",
    "        fn = folowingLayer.getLayer()[i]\n",
    "        dE_dyi = fn.getDelta()\n",
    "        dxi_dyj = (1-fn.getWeights()[neuronNumber]) * np.prod(np.delete(fn.getMus(), neuronNumber))\n",
    "        \n",
    "        dE_dy -= dE_dyi * dxi_dyj\n",
    "        \n",
    "    neuron.setDelta(dE_dy)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        dx_dw = (1 - neuron.getWeights()[i]) * np.prod(np.delete(neuron.getMus(), i))\n",
    "        \n",
    "        grad[i] = -dE_dy * dx_dw\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "    \n",
    "def gradientOutputLayer(neuron, target, prediction):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    dE_dy = -(target - prediction)\n",
    "        \n",
    "    for i in range(0, numWeights):\n",
    "        dx_dw = (1 - neuron.getWeights()[i]) * np.prod(np.delete(neuron.getMus(), i))\n",
    "        \n",
    "        grad[i] = -dE_dy * dx_dw\n",
    "\n",
    "    neuron.setDelta(dE_dy)\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNANDNetwork(data, targets, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    print(network)\n",
    "    print(\"Initial Loss: \", MSE(network, data, targets))\n",
    "    \n",
    "    for i in range(1, 100000):   \n",
    "        if (MSE(network, data, targets) < 0.0000000000001):\n",
    "            break\n",
    "            \n",
    "        for j in range(0, len(data)):\n",
    "            prediction = network.fowardprop(data[j])\n",
    "            network.backprop(prediction, targets[j])\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(network, data, targets))\n",
    "    return network\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [ 0.  0.] ,[ 0.  0.] ,\n",
      "Layer 2 -> [ 0.  0.] ,\n",
      "\n",
      "Initial Loss:  1.0\n",
      "Trained Loss:  0.375044117233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [ 1.  1.] ,[ 1.  1.] ,\n",
       "Layer 2 -> [ 0.49528107  0.49528107] ,"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAND Gate Data\n",
    "# data = np.array([[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
    "# targets = np.array([1.0,1.0,1.0,0.0])\n",
    "\n",
    "\n",
    "\n",
    "# NOT Gate Data\n",
    "# data = np.array([[0.0, 1.0], [1.0, 1.0]])\n",
    "# targets = np.array([1.0, 0.0])\n",
    "# trainNANDNetwork(data, targets, 2, [], 1)\n",
    "\n",
    "\n",
    "# AND Gate Data\n",
    "# data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "# targets = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "\n",
    "# OR Gate Data \n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "targets = np.array([0.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "trainNANDNetwork(data, targets, 2, [2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
