{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NANDNeuron():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.epsilons = np.full((n), -1.0) #np.random.uniform(-1.0, 1.001, n)#\n",
    "        self.effector = -1\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.epsilons)\n",
    "        \n",
    "    def __beforePresent__(self):\n",
    "        self.effector = -1\n",
    "        self.delta = 0\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "    \n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "    \n",
    "    def present(self, inputs):\n",
    "        self.__beforePresent__()\n",
    "        mus = np.maximum(self.epsilons, inputs)\n",
    "        self.mus = mus\n",
    "        self.inputs = inputs\n",
    "        out = np.min(mus)\n",
    "        \n",
    "        # Determin which had effect\n",
    "        for i in range(0, len(mus)):\n",
    "            if out == mus[i]:\n",
    "                self.effector = i\n",
    "        \n",
    "        self.output = -out\n",
    "        return self.output\n",
    "\n",
    "    def getInput(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    def getMus(self):\n",
    "        return self.mus\n",
    "    \n",
    "    def getOutput(self):\n",
    "        return self.output\n",
    "    \n",
    "    def updateWeights(self, grad):\n",
    "        self.epsilons = self.epsilons - grad\n",
    "        for i in range(0, len(self.epsilons)):\n",
    "            if self.epsilons[i] > 1:\n",
    "                self.epsilons[i] = 1\n",
    "            elif self.epsilons[i] < -1:\n",
    "                self.epsilons[i] = -1\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.epsilons\n",
    "    \n",
    "    def getEffector(self):\n",
    "        return self.effector\n",
    "\n",
    "class NANDLayer():\n",
    "    def __init__(self, inputs, nodes):\n",
    "        self.layer = []\n",
    "        \n",
    "        for i in range(0, nodes):\n",
    "            self.layer.append(NANDNeuron(inputs))\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in self.layer:\n",
    "            s += (str(l) + \" ,\")\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def getLayer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def setFolowingLayer(self, l):\n",
    "        self.folowingLayer = l\n",
    "        \n",
    "    def present(self, inputs):\n",
    "        out = []\n",
    "        for n in self.layer:\n",
    "            out.append(n.present(inputs))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backprop(self, prediction, target, output=False):\n",
    "        for n in range(0, len(self.layer)):\n",
    "            grad = None\n",
    "            if output:\n",
    "                grad = gradientOutputLayer(self.layer[n], target, prediction)\n",
    "            else:\n",
    "                grad = gradientHiddenLayer(self.layer[n], n, self.folowingLayer)\n",
    "                \n",
    "            self.layer[n].updateWeights(grad * 0.05)\n",
    "    \n",
    "class NANDNetwork():\n",
    "    def __init__(self, nIns, lParams, nOuts):\n",
    "        self.layers = []\n",
    "        \n",
    "        lParams.append(nOuts)\n",
    "        inputs = nIns\n",
    "        for l in lParams:\n",
    "            self.layers.append(NANDLayer(inputs, l))\n",
    "            inputs = l\n",
    "                    \n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i-1].setFolowingLayer(self.layers[i])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for l in range(0, len(self.layers)):\n",
    "            s += (\"Layer \" + str(l+1) + \" -> \" + str(self.layers[l]) + \"\\n\")\n",
    "            \n",
    "        return s\n",
    "        \n",
    "    def fowardprop(self, inputs):\n",
    "        for l in self.layers:\n",
    "            inputs = l.present(inputs)\n",
    "            \n",
    "        return inputs[0]\n",
    "            \n",
    "    def backprop(self, prediction, target):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            layer.backprop(prediction, target, i==(len(self.layers) - 1))\n",
    "    \n",
    "    \n",
    "def MSE(network, data, targets):\n",
    "    expected = np.array(list(map(lambda x: network.fowardprop(x), data)))\n",
    "#     print(expected)\n",
    "    return (1.0/2.0) * np.sum(np.power(np.subtract(expected, targets), 2))\n",
    "\n",
    "def gradientHiddenLayer(neuron, neuronNumber, folowingLayer):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    # Compute the delta of current node\n",
    "    dE_dy = 0\n",
    "    for i in range(0, len(folowingLayer.getLayer())):\n",
    "        fn = folowingLayer.getLayer()[i]\n",
    "        dE_dyi = fn.getDelta()\n",
    "        \n",
    "        if fn.getEffector() == neuronNumber:\n",
    "            if not fn.getInput()[neuronNumber] == neuron.getOutput():\n",
    "                print(\"ERRRRRORRORORO\")\n",
    "                \n",
    "            dxi_dyi = (fn.getWeights()[neuronNumber] - fn.getInput()[neuronNumber])\n",
    "            dE_dy += (dE_dyi * dxi_dyi)\n",
    "        \n",
    "        \n",
    "    neuron.setDelta(dE_dy)\n",
    "    \n",
    "    for i in range(0, numWeights):\n",
    "        dx_dw = 0\n",
    "        if neuron.getEffector() == i:\n",
    "            dx_dw = -(neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "        \n",
    "        grad[i] = dE_dy * dx_dw\n",
    "    \n",
    "#     for i in range(0, len(folowingLayer.getLayer())):\n",
    "#         fowardNeuron = folowingLayer.getLayer()[i]\n",
    "        \n",
    "#         dE_dyi = fowardNeuron.getDelta()\n",
    "#         dxi_dmui = np.min(np.delete(fowardNeuron.getMus(), neuronNumber)) - fowardNeuron.getMus()[neuronNumber]\n",
    "#         dmui_dyi = neuron.getOutput() - fowardNeuron.getWeights()[neuronNumber]\n",
    "#         dxi_dyi = dxi_dmui * dmui_dyi\n",
    "#         dE_dy += dE_dyi * dxi_dyi\n",
    "    \n",
    "#     for i in range(0, numWeights):\n",
    "#         dx_dmu = np.min(np.delete(neuron.getMus(), i)) - neuron.getMus()[i]\n",
    "#         dmu_dw = neuron.getWeights()[i] - neuron.getInput()[i]\n",
    "#         dx_dw = dx_dmu * dmu_dw\n",
    "        \n",
    "#         grad[i] = -dE_dy * dx_dw\n",
    "# #         grad[i] = dE_dy * deltaW(i, neuron) * (neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "        \n",
    "    neuron.setDelta(dE_dy)\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "    \n",
    "def gradientOutputLayer(neuron, target, prediction):\n",
    "    numWeights = len(neuron.getWeights())\n",
    "    grad = np.zeros(numWeights)\n",
    "    \n",
    "    dE_dy = -(target - prediction)\n",
    "#     for i in range(0, numWeights):\n",
    "#         dx_dmu = np.min(np.delete(neuron.getMus(), i)) - neuron.getMus()[i]\n",
    "#         dmu_dw = neuron.getWeights()[i] - neuron.getInput()[i]\n",
    "#         dx_dw = dx_dmu * dmu_dw\n",
    "        \n",
    "#         grad[i] = dE_dy * dx_dw\n",
    "#         grad[i] = dE_dy * deltaW(i, neuron) * (neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "        \n",
    "    for i in range(0, numWeights):\n",
    "        dx_dw = 0\n",
    "        if neuron.getEffector() == i:\n",
    "            dx_dw = -(neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "        \n",
    "        grad[i] = dE_dy * dx_dw\n",
    "\n",
    "    neuron.setDelta(dE_dy)\n",
    "#     print(grad)\n",
    "    return grad\n",
    "\n",
    "# Compute W_{a,b}\n",
    "# def deltaW(i, neuron):\n",
    "#     muBs = np.delete(neuron.getMus(), i)\n",
    "#     print()\n",
    "#     print(neuron.getMus())\n",
    "#     print(muBs)\n",
    "#     print(neuron.getMus()[i])\n",
    "#     t = (np.min(muBs) - neuron.getMus()[i]) * (neuron.getWeights()[i] - neuron.getInput()[i])\n",
    "#     print(t)\n",
    "#     return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNANDNetwork(data, targets, inputNodes, hLayers, outNodes):\n",
    "    network = NANDNetwork(inputNodes, hLayers, outNodes)\n",
    "    print(network)\n",
    "    print(\"Initial Loss: \", MSE(network, data, targets))\n",
    "    \n",
    "    for i in range(1, 100000):\n",
    "        \n",
    "        if (MSE(network, data, targets) < 0.0000000000001):\n",
    "            break\n",
    "#         if i%1000 == 0:\n",
    "#             print(\"Iteration -> \" + str(i))\n",
    "            \n",
    "        for j in range(0, len(data)):\n",
    "            prediction = network.fowardprop(data[j])\n",
    "            network.backprop(prediction, targets[j])\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(network, data, targets))\n",
    "    return network\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 -> [-1. -1.] ,[-1. -1.] ,\n",
      "Layer 2 -> [-1. -1.] ,\n",
      "\n",
      "Initial Loss:  4.0\n",
      "Trained Loss:  4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1 -> [-1. -1.] ,[-1. -1.] ,\n",
       "Layer 2 -> [-1.  1.] ,"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAND Gate Data\n",
    "# data = np.array([[-1.0,-1.0],[1.0,-1.0],[-1.0,1.0],[1.0,1.0]])\n",
    "# targets = np.array([1.0,1.0,1.0,-1.0])\n",
    "\n",
    "\n",
    "\n",
    "# NOT Gate Data\n",
    "# data = np.array([[-1.0, 1.0], [1.0, 1.0]])\n",
    "# targets = np.array([1.0, -1.0])\n",
    "# trainNANDNetwork(data, targets, 2, [], 1)\n",
    "\n",
    "\n",
    "# AND Gate Data\n",
    "# data = np.array([[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0]])\n",
    "# targets = np.array([-1.0, -1.0, -1.0, 1.0])\n",
    "\n",
    "# OR Gate Data \n",
    "data = np.array([[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0]])\n",
    "targets = np.array([-1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "trainNANDNetwork(data, targets, 2, [2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
