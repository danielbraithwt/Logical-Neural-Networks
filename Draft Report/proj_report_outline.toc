\select@language {english}
\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Motivation}{1}
\contentsline {section}{\numberline {1.2}Solution}{2}
\contentsline {chapter}{\numberline {2}Background}{3}
\contentsline {section}{\numberline {2.1}Intepretability}{3}
\contentsline {subsection}{\numberline {2.1.1}Relation to Solution}{4}
\contentsline {section}{\numberline {2.2}Rule Extraction}{4}
\contentsline {section}{\numberline {2.3}LIME: Local Interpretable Model-Agnostic Explanations}{4}
\contentsline {section}{\numberline {2.4}Noisy Neurons}{5}
\contentsline {section}{\numberline {2.5}Logical Normal Form Networks}{7}
\contentsline {subsection}{\numberline {2.5.1}CNF \& DNF}{7}
\contentsline {subsection}{\numberline {2.5.2}CNF \& DNF from Truth Table}{7}
\contentsline {subsection}{\numberline {2.5.3}Definition of Logical Normal Form Networks}{8}
\contentsline {section}{\numberline {2.6}Logical Neural Networks}{8}
\contentsline {section}{\numberline {2.7}Learning Fuzzy Logic Operations in Deep Neural Networks}{8}
\contentsline {chapter}{\numberline {3}Foundation of Logical Normal Form Networks}{9}
\contentsline {section}{\numberline {3.1}Noisy Gate Parametrisation}{10}
\contentsline {section}{\numberline {3.2}Training LNF Networks}{11}
\contentsline {subsection}{\numberline {3.2.1}Weight Initialization}{12}
\contentsline {paragraph}{Deriving a Distribution For The Weights}{12}
\contentsline {paragraph}{Fitting To Log Normal}{14}
\contentsline {paragraph}{Weight Initialization Algorithm}{15}
\contentsline {subsection}{\numberline {3.2.2}Training Algorithm}{15}
\contentsline {subsection}{\numberline {3.2.3}Batch Size}{15}
\contentsline {section}{\numberline {3.3}LNF Network Performance}{15}
\contentsline {section}{\numberline {3.4}LNF Network Generalization}{16}
\contentsline {section}{\numberline {3.5}LNF Network Rule Extraction}{16}
\contentsline {section}{\numberline {3.6}Summary}{18}
\contentsline {chapter}{\numberline {4}Expanding the Problem Domain of Logical Normal Form Networks}{19}
\contentsline {section}{\numberline {4.1}Multi-class Classification}{19}
\contentsline {subsection}{\numberline {4.1.1}Application to Lenses Problem}{19}
\contentsline {section}{\numberline {4.2}Features with Continuous Domains}{21}
\contentsline {paragraph}{Influence Model}{21}
\contentsline {paragraph}{Partial Influence Models}{22}
\contentsline {paragraph}{Continous Rules}{22}
\contentsline {subsection}{\numberline {4.2.1}Application To Iris Problem}{22}
\contentsline {section}{\numberline {4.3}Summary}{23}
\contentsline {chapter}{\numberline {5}Logical Neural Networks}{25}
\contentsline {section}{\numberline {5.1}Modified Logical Neural Network}{25}
\contentsline {subsection}{\numberline {5.1.1}Connections Between Layers \& Parameters}{25}
\contentsline {subsection}{\numberline {5.1.2}Softmax Output Layer}{26}
\contentsline {chapter}{\numberline {6}Evaluation Of Logical Neural Networks}{27}
\contentsline {section}{\numberline {6.1}Performance of Logical Neural Networks}{27}
\contentsline {paragraph}{Results}{28}
\contentsline {section}{\numberline {6.2}Intepretability of Logical Neural Networks}{29}
\contentsline {subsection}{\numberline {6.2.1}Discrete Case (Rule Extraction)}{29}
\contentsline {subsubsection}{Evaluation of LNN Rules}{30}
\contentsline {subsection}{\numberline {6.2.2}Continuous Case}{30}
\contentsline {subsubsection}{No Hidden Layer Networks}{31}
\contentsline {paragraph}{Sigmoid Network}{31}
\contentsline {paragraph}{AND Network Old Architecture (With and With Out LSM)}{31}
\contentsline {paragraph}{AND Network (With LSM)}{32}
\contentsline {paragraph}{AND Network (With out LSM)}{33}
\contentsline {paragraph}{Conclusion of Intepretability for LNNs with No Hidden Layer}{33}
\contentsline {subsubsection}{Single Hidden Layer Networks}{33}
\contentsline {paragraph}{Sigmoid Network}{33}
\contentsline {paragraph}{OR $\rightarrow $ AND Network Old Structure (With Out LSM)}{34}
\contentsline {paragraph}{OR $\rightarrow $ AND Network Old Structure (With LSM)}{34}
\contentsline {paragraph}{OR $\rightarrow $ AND Network (With Out LSM)}{35}
\contentsline {paragraph}{OR $\rightarrow $ AND (With LSM)}{35}
\contentsline {paragraph}{AND $\rightarrow $ OR Model (With Out LSM)}{36}
\contentsline {paragraph}{AND $\rightarrow $ OR Model (With LSM)}{36}
\contentsline {paragraph}{Conclusion of Intepretability for LNNs with No Hidden Layer}{37}
\contentsline {subsection}{\numberline {6.2.3}Results of Intepretability Experiments}{37}
\contentsline {section}{\numberline {6.3}Comparason Between LNNs and Exsisting Methods}{37}
\contentsline {subsection}{\numberline {6.3.1}Comparison between LNN Intepretability and LIME}{37}
\contentsline {subsection}{\numberline {6.3.2}Comparason Between LNNs and Fuzzy Logic Networks}{38}
\contentsline {section}{\numberline {6.4}Summary Of Logical Neural Network Evaluation}{38}
\contentsline {chapter}{\numberline {7}Application to Auto Encoders}{40}
\contentsline {paragraph}{Result of Linear Autoencoder (LAE)}{40}
\contentsline {paragraph}{Result of Sigmoid Auto Encoder (SAE)}{40}
\contentsline {paragraph}{Result of Logical Auto Encoder (LoAE)}{41}
\contentsline {paragraph}{Discussion}{41}
\contentsline {chapter}{\numberline {8}Conclusion}{42}
\contentsline {chapter}{Appendices}{45}
\contentsline {chapter}{\numberline {A}Proofs}{46}
\contentsline {section}{\numberline {A.1}Proof Of Theorem \ref {thm:upper-bound-hidden-units}}{46}
