\select@language {english}
\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Motivation}{1}
\contentsline {section}{\numberline {1.2}Solution}{2}
\contentsline {chapter}{\numberline {2}Background}{3}
\contentsline {section}{\numberline {2.1}Interpretability}{3}
\contentsline {section}{\numberline {2.2}Rule Extraction}{4}
\contentsline {section}{\numberline {2.3}LIME: Local Interpretable Model-Agnostic Explanations}{4}
\contentsline {section}{\numberline {2.4}Noisy Neurons}{5}
\contentsline {section}{\numberline {2.5}Logical Normal Form Networks}{7}
\contentsline {subsection}{\numberline {2.5.1}CNF \& DNF}{7}
\contentsline {subsection}{\numberline {2.5.2}CNF \& DNF from Truth Table}{7}
\contentsline {subsection}{\numberline {2.5.3}Definition of Logical Normal Form Networks}{8}
\contentsline {section}{\numberline {2.6}Logical Neural Networks}{8}
\contentsline {section}{\numberline {2.7}Learning Fuzzy Logic Operations in Deep Neural Networks}{8}
\contentsline {chapter}{\numberline {3}Foundation of Logical Normal Form Networks}{9}
\contentsline {section}{\numberline {3.1}Noisy Gate Parametrisation}{10}
\contentsline {section}{\numberline {3.2}Training LNF Networks}{11}
\contentsline {subsection}{\numberline {3.2.1}Weight Initialization}{12}
\contentsline {paragraph}{Deriving a Distribution For The Weights}{12}
\contentsline {paragraph}{Fitting To Log Normal}{14}
\contentsline {paragraph}{Weight Initialization Algorithm}{15}
\contentsline {subsection}{\numberline {3.2.2}Training Algorithm}{15}
\contentsline {subsection}{\numberline {3.2.3}Batch Size}{15}
\contentsline {section}{\numberline {3.3}LNF Network Performance}{15}
\contentsline {section}{\numberline {3.4}LNF Network Generalization}{16}
\contentsline {section}{\numberline {3.5}LNF Network Rule Extraction}{16}
\contentsline {section}{\numberline {3.6}Summary}{18}
\contentsline {chapter}{\numberline {4}Expanding the Problem Domain of Logical Normal Form Networks}{19}
\contentsline {section}{\numberline {4.1}Multi-class Classification}{19}
\contentsline {subsection}{\numberline {4.1.1}Application to Lenses Problem}{19}
\contentsline {section}{\numberline {4.2}Features with Continuous Domains}{20}
\contentsline {paragraph}{Influence Model.}{21}
\contentsline {paragraph}{Partial Influence Models}{21}
\contentsline {paragraph}{Continuous Rules}{21}
\contentsline {subsection}{\numberline {4.2.1}Application To Iris Problem}{22}
\contentsline {section}{\numberline {4.3}Summary}{23}
\contentsline {chapter}{\numberline {5}Logical Neural Networks}{24}
\contentsline {section}{\numberline {5.1}Modified Logical Neural Network}{24}
\contentsline {subsection}{\numberline {5.1.1}Connections Between Layers \& Parameters}{24}
\contentsline {subsection}{\numberline {5.1.2}Softmax Output Layer}{25}
\contentsline {chapter}{\numberline {6}Evaluation Of Logical Neural Networks}{26}
\contentsline {section}{\numberline {6.1}Performance of Logical Neural Networks}{26}
\contentsline {paragraph}{Results}{27}
\contentsline {section}{\numberline {6.2}Interpretability of Logical Neural Networks}{28}
\contentsline {subsection}{\numberline {6.2.1}Discrete Case}{28}
\contentsline {subsubsection}{Evaluation of LNN Rules}{29}
\contentsline {subsection}{\numberline {6.2.2}Continuous Case}{29}
\contentsline {subsubsection}{No Hidden Layer Networks}{30}
\contentsline {paragraph}{Sigmoid Network}{30}
\contentsline {paragraph}{AND Network Old Architecture (With and With Out LSM)}{30}
\contentsline {paragraph}{AND Network (With LSM)}{31}
\contentsline {paragraph}{AND Network (Without LSM)}{32}
\contentsline {paragraph}{Conclusion of Interpretability for LNNs with No Hidden Layer}{32}
\contentsline {subsubsection}{Single Hidden Layer Networks}{32}
\contentsline {paragraph}{Sigmoid Network}{32}
\contentsline {paragraph}{OR $\rightarrow $ AND Network Old Structure (With Out LSM)}{33}
\contentsline {paragraph}{OR $\rightarrow $ AND Network Old Structure (With LSM)}{33}
\contentsline {paragraph}{OR $\rightarrow $ AND Network (With Out LSM)}{34}
\contentsline {paragraph}{OR $\rightarrow $ AND (With LSM)}{34}
\contentsline {paragraph}{AND $\rightarrow $ OR Model (With Out LSM)}{35}
\contentsline {paragraph}{AND $\rightarrow $ OR Model (With LSM)}{35}
\contentsline {paragraph}{Conclusion of Interpretability for LNNs with One Hidden Layer}{36}
\contentsline {subsection}{\numberline {6.2.3}Results of Interpretability Experiments}{36}
\contentsline {section}{\numberline {6.3}Comparison Between LNNs and Existing Methods}{36}
\contentsline {subsection}{\numberline {6.3.1}Comparison between LNN Interpretability and LIME}{36}
\contentsline {subsection}{\numberline {6.3.2}Comparison Between LNNs and Fuzzy Logic Networks}{37}
\contentsline {section}{\numberline {6.4}Summary Of Logical Neural Network Evaluation}{38}
\contentsline {chapter}{\numberline {7}Application to Autoencoders}{39}
\contentsline {paragraph}{Result of Linear Autoencoder (LAE)}{39}
\contentsline {paragraph}{Result of Sigmoid Auto Encoder (SAE)}{39}
\contentsline {paragraph}{Result of Logical Auto Encoder (LoAE)}{40}
\contentsline {paragraph}{Discussion}{40}
\contentsline {chapter}{\numberline {8}Conclusion}{41}
\contentsline {chapter}{Appendices}{44}
\contentsline {chapter}{\numberline {A}Proofs}{45}
\contentsline {section}{\numberline {A.1}Proof Of Theorem \ref {thm:upper-bound-hidden-units}}{45}
