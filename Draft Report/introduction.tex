\chapter{Introduction}\label{C:intro}

Artificial Neural Networks (ANN's) are commonly used to model supervised learning problems. A well trained ANN can generalize well but it is very difficult to interpret how the network is operating. This issue with intepretability makes ANNs black-boxes. This report aims to aliveate this problem by formalizing and developing a novel neural network archetchure.

\section{Motivation}
The number of situations in which ANN systems are used is growing. This has lead to an increasing interest in systems which are not only accurate but also provide a means to understand the logic use to derive their answers \cite{doshi2017towards}. Interest in interpretable systems is driven by the variety of situations that utilize ANNs where incorrect or biased answers can have significant effects on users.\\

Ensuring a system is Safe and Ethical are two things which, depending on the application, are important to verify. If an ANN was able to provide its reasoning for giving a specific output then defending the actions of the system would be more feasible \cite{doshi2017towards}.\\

In the context of safety a Machine Learning (ML) system often can not be tested against all possible situations as it is computationally infeasible, consequently, if accessible , the logic contained inside the mode could be used to verify the safety of the system.\\

It is also important to consider the implications of an ANN being biased towards a protected class of people. A paper published in 2017 demonstrated that standard machine learning algorithms trained over text data learn stereotyped biases which occur in humans \cite{caliskan2017semantics}. An ANN trained with the intent to be fair could result in a system which discriminates unfairly because of biases in the data used to train it.\\

Another pressure causing the development of this field is changing laws. In 2018 the European Union (EU) General Data Protection Regulation (GDPR or "right to explanation") will come into affect requiring algorithms which profile users based on their personal information be able to provide "Meaningful information about the logic involved"  \cite{eu-dgpr}. This law would effect a number of situations where ML systems are used, for example banks, which use ML systems to make loan application decisions \cite{goodman2016european}.\\

Consider the following example of uncertainty bias \cite{goodman2016european}. The application is designing an ANN to make loan decisions. The decision to grant a loan is made by computing a 95\% confidence interval of the probability of repayment, then checking that the lower end of the interval is above 90\%. A number of data sets are generated for this algorithm to be trained on. The datasets are split into white and non-white individuals each with the same average probability of repayment. As the ratio of white to non-white individuals increases the algorithm is less likely to grant loans to non-white individuals despite the repayment rate being equal. This artificial situation demonstrates the effect biased data could have on an ANN.\\

The argument thus far has established that being able to defend or verify the decisions made by ANNs is just an interesting academic question. It would allow for the possibility to check systems for possible safety risks or an unfair bias against a certain class of people \cite{goodman2016european}. On the other hand the GDPR could make it difficult for companies to use ML systems as breaches of the regulation could incur large fines.

\section{State Of Field}
Growing applications and changing laws are applying pressure to the field of Machine Learning to develop more interpretable systems. There exists a rich literature of methods to extract rules from ANNs, most techniques are flexible and do not place many restrictions on the network architecture \cite{andrews1995survey} \cite{duch2004computational} \cite{tsukimoto2000extracting}. The rule extraction algorithms become more complicated and computationally inefficient as the restrictions placed on architecture decrease.\\

\section{Solution}
To address the problems laid out thus far we improved upon a probability based network architecture called Logical Neural Networks which yield a simpler trained model \cite{LearningLogicalActivations} and in cases where the inputs and outputs are boolean values the network can be converted to a set of rules with little effort.\\

This report presents a formal grounding for Logical Neural Networks through the following stages
\begin{enumerate}
	\item Motivate the concept of noisy neurons and derive them.
	\item Motivate and derive at a very specific case of Logical Neural Networks called Logical Normal Form Networks.
	\item Discuss the performance, generalization and interpretation capabilities of Logical Normal Form Networks.
	\item Generalise Logical Normal Form Networks to Logical Neural Networks.
	\item Derive modifications to the Logical Neural Network architecture to improve accuracy
	\item Demonstrate the possible use cases of Logical Neural Networks.
\end{enumerate}

 The report proposes a modified structure which is able to obtain better performance that what was previously achieved.