\chapter{Introduction}\label{C:intro}
Neural Networks (NN's) are commenly used to model supervised learning problems. NN's often achieve higher accuracy than other methods because they are able to approximate any continous function. A well trained NN can generalize well but it is very diffcult to intepret how the network is operating. This is called the black-box problem. Rule extraction algorythms have been developed to address this problem, some aim to extract rules to replace the NN and others extract rules which are combined with the NN to improve peformance.\\

There are a number of motivations for wanting to solve the black-box problem. If a NN is able to provide an explination for its output by inspecting the reasoning a deeper understanding of the problem can be developed, the rules learnt by an NN could represent some knolwedge or patten in the data which has not yet been identifyed. Another possibility is that the neural network is being implemented to operate a critical systems which involve the saftey of humans, in this case being able to extract rules and inspect the NN is a necessary part of ensuring the system is safe.\\

Rule extraction algorythms are generally split into three categories. The \textbf{Decompositional Approach} extracts rules by analysing the activations and weights in the hidden layers. The \textbf{Pedagogical Approach} works by creating a mapping of the relationship beween inputs and outputs. Finally The \textbf{Eclectic Approach} combines the previous two approaches.\\

By restricting the function set that each neuron can peform is it possible to create a more intepretable network? Restricted the functions for each neuron to be the function set taking some subset of inputs and peform a pre determined logical function, after training to identify the function each neuron is peforming on its inputs only the subset of inputs considered must be identified as the operation is fixed.\\

This report develops a decompositional approach to rule extraction which allows boolean expressions to be infered from a network with little effort once training has finished.\\

Neurons are restricted to peforming only AND's or OR's on some subset of their inputs, then placed in a confguration which allows learning Conjunctive Normal Form or Disjunctive Normal Form expressions, such networks are called Logical Normal Form (LNF) Networks.\\

When provided a truth table for a boolean expression, the peformance of LNFN's has no stistically significant differnces to that of a Multi-Layer Perceptron (MLPN) Network. The LNFN's are also able to generalize, obtaining stistically equal peformances as a MLPN when given incomplete truth tables.\\

Once trained an LNFN's weights directly corospond to the subset of inputs being acted on. A rule extraction algorythm can be defined which simply inspects the weights of each neuron to extract a boolean representing the network.\\

The restriction placed on the function space of each neuron, while improving the interpretability, intuatively will also hinder their ability to be universal approximators. Along with the development of a new rule extraction approach this report will identify and explore the issues introduced by the restrction placed on neurons to determin where the rule extraction algorythm can be used.\\

